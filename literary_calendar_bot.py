"""
Telegram-–±–æ—Ç –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞—Å—Å—ã–ª–∫–∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –¥–∞—Ç –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
—Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∫–Ω–∏–≥–∏ –∏–∑ API "–°–≤–µ—Ç"
"""

import asyncio
import logging
import re
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from urllib.parse import urlparse, parse_qs

import httpx
from telegram import Bot
from telegram.error import TelegramError

try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


class LiteraryCalendarBot:
    """–ë–æ—Ç –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –¥–∞—Ç"""
    
    def __init__(
        self,
        bot_token: str,
        calendar_url: str,
        graphql_endpoint: str,
        group_chat_id: str,
        timezone: str = "Europe/Moscow"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
        
        Args:
            bot_token: –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞
            calendar_url: URL –∫–∞–ª–µ–Ω–¥–∞—Ä—è Yandex Calendar
            graphql_endpoint: URL GraphQL API
            group_chat_id: ID –≥—Ä—É–ø–ø—ã –≤ Telegram (–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ @userinfobot)
            timezone: –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å
        """
        self.bot = Bot(token=bot_token)
        self.calendar_url = calendar_url
        self.graphql_endpoint = graphql_endpoint
        self.group_chat_id = group_chat_id
        self.timezone = timezone
        
    async def fetch_calendar(self) -> str:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä—å –∏–∑ Yandex Calendar"""
        async with httpx.AsyncClient() as client:
            response = await client.get(self.calendar_url)
            if response.status_code == 200:
                return response.text
            else:
                raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—è: {response.status_code}")
    
    def parse_calendar(self, xml_content: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç XML –∫–∞–ª–µ–Ω–¥–∞—Ä—å –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π —Å –¥–∞—Ç–∞–º–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
        return self._simple_parse(xml_content)
    
    def _simple_parse(self, content: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–ª–µ–Ω–¥–∞—Ä—è Yandex Calendar (HTML —Ñ–æ—Ä–º–∞—Ç)"""
        events = []
        
        # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å BeautifulSoup –¥–ª—è HTML –ø–∞—Ä—Å–∏–Ω–≥–∞
        if HAS_BS4:
            return self._parse_html_bs4(content)
        
        # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å #)
            if line.startswith('# '):
                title = line[2:].strip()
                event = {
                    'title': title,
                    'start_date': None,
                    'end_date': None,
                    'description': '',
                    'author_uuids': [],
                    'tags': [],
                    'links': []
                }
                
                # –ò—â–µ–º –¥–∞—Ç—É –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö (–æ–±—ã—á–Ω–æ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞)
                for j in range(i + 1, min(i + 5, len(lines))):
                    date_line = lines[j].strip()
                    
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –≤–∏–¥–∞ "6 –¥–µ–∫–∞–±—Ä—è 2025 00:00 7 –¥–µ–∫–∞–±—Ä—è 2025 00:00"
                    # –∏–ª–∏ "6 –¥–µ–∫–∞–±—Ä—è 2025 00:00"
                    date_patterns = [
                        r'(\d{1,2})\s+(\w+)\s+(\d{4})\s+(\d{2}:\d{2})',  # –ü–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
                        r'(\d{1,2})\s+(\w+)\s+(\d{4})',  # –ë–µ–∑ –≤—Ä–µ–º–µ–Ω–∏
                    ]
                    
                    for pattern in date_patterns:
                        date_match = re.search(pattern, date_line)
                        if date_match:
                            day, month_ru, year = date_match.groups()[:3]
                            time_str = date_match.group(4) if len(date_match.groups()) > 3 else "00:00"
                            
                            try:
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä—É—Å—Å–∫–∏–µ –º–µ—Å—è—Ü—ã
                                months_ru = {
                                    '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
                                    '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
                                    '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12,
                                    '—è–Ω–≤–∞—Ä—å': 1, '—Ñ–µ–≤—Ä–∞–ª—å': 2, '–º–∞—Ä—Ç': 3, '–∞–ø—Ä–µ–ª—å': 4,
                                    '–º–∞–π': 5, '–∏—é–Ω—å': 6, '–∏—é–ª—å': 7, '–∞–≤–≥—É—Å—Ç': 8,
                                    '—Å–µ–Ω—Ç—è–±—Ä—å': 9, '–æ–∫—Ç—è–±—Ä—å': 10, '–Ω–æ—è–±—Ä—å': 11, '–¥–µ–∫–∞–±—Ä—å': 12
                                }
                                month = months_ru.get(month_ru.lower())
                                if month:
                                    hour, minute = map(int, time_str.split(':'))
                                    event['start_date'] = datetime(int(year), month, int(day), hour, minute)
                                    break
                            except (ValueError, KeyError) as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{date_line}': {e}")
                    
                    if event['start_date']:
                        break
                
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö
                description_lines = []
                for j in range(i + 1, min(i + 15, len(lines))):
                    link_line = lines[j]
                    
                    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ example.com
                    if 'example.com' in link_line:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ URL –∏–∑ —Å—Ç—Ä–æ–∫–∏
                        urls = re.findall(r'https?://[^\s<>"\)]+', link_line)
                        for url in urls:
                            if url not in event['links']:
                                event['links'].append(url)
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ URL
                            try:
                                parsed_url = urlparse(url)
                                query_params = parse_qs(parsed_url.query)
                                
                                if 'authors' in query_params:
                                    event['author_uuids'].extend(query_params['authors'])
                                if 'tags' in query_params:
                                    event['tags'].extend(query_params['tags'])
                                
                                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º slug –≤ –ø—É—Ç–∏
                                path_parts = parsed_url.path.strip('/').split('/')
                                if len(path_parts) > 1 and path_parts[0] == 'catalog':
                                    # –ú–æ–∂–µ—Ç –±—ã—Ç—å slug –∫–Ω–∏–≥–∏ –∏–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                                    pass
                            except Exception as e:
                                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL '{url}': {e}")
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (—Ç–µ–∫—Å—Ç –º–µ–∂–¥—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ–∫—Ü–∏–µ–π)
                    elif link_line.strip() and not link_line.strip().startswith('#'):
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞—Ç–∞–º–∏
                        if not re.search(r'\d{1,2}\s+\w+\s+\d{4}', link_line):
                            desc_text = link_line.strip()
                            if desc_text and desc_text not in description_lines:
                                description_lines.append(desc_text)
                    
                    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–µ
                    if j < len(lines) - 1 and lines[j + 1].strip().startswith('# '):
                        break
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                if description_lines:
                    event['description'] = '\n'.join(description_lines[:3])  # –ú–∞–∫—Å–∏–º—É–º 3 —Å—Ç—Ä–æ–∫–∏
                
                events.append(event)
            i += 1
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π: {len(events)}")
        return events
    
    def _parse_html_bs4(self, html_content: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ HTML –∫–∞–ª–µ–Ω–¥–∞—Ä—è —Å –ø–æ–º–æ—â—å—é BeautifulSoup"""
        events = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è (div —Å –∫–ª–∞—Å—Å–æ–º b-content-event)
            event_divs = soup.find_all('div', class_='b-content-event')
            
            for event_div in event_divs:
                event = {
                    'title': '',
                    'start_date': None,
                    'end_date': None,
                    'description': '',
                    'author_uuids': [],
                    'tags': [],
                    'links': []
                }
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–±—ã—Ç–∏—è (h1)
                h1 = event_div.find('h1')
                if h1:
                    event['title'] = h1.get_text(strip=True)
                
                # –î–∞—Ç–∞ (div —Å –∫–ª–∞—Å—Å–æ–º e-time)
                time_div = event_div.find('div', class_='e-time')
                if time_div:
                    time_spans = time_div.find_all('span')
                    if time_spans and len(time_spans) >= 1:
                        date_str = time_spans[0].get_text(strip=True)
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –≤–∏–¥–∞ "6 –¥–µ–∫–∞–±—Ä—è 2025 00:00"
                        event['start_date'] = self._parse_date_string(date_str)
                
                # –û–ø–∏—Å–∞–Ω–∏–µ (div —Å –∫–ª–∞—Å—Å–æ–º e-description)
                desc_div = event_div.find('div', class_='e-description')
                if desc_div:
                    # –¢–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è
                    desc_text = desc_div.get_text(strip=True)
                    if desc_text:
                        event['description'] = desc_text
                    
                    # –°—Å—ã–ª–∫–∏
                    links = desc_div.find_all('a', href=True)
                    for link in links:
                        url = link.get('href', '')
                        if url:
                            event['links'].append(url)
                            
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º UUID –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ —Å—Å—ã–ª–æ–∫
                            parsed_url = urlparse(url)
                            query_params = parse_qs(parsed_url.query)
                            
                            if 'authors' in query_params:
                                event['author_uuids'].extend(query_params['authors'])
                            if 'tags' in query_params:
                                event['tags'].extend(query_params['tags'])
                
                if event['title']:
                    events.append(event)
            
            logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π —á–µ—Ä–µ–∑ BeautifulSoup: {len(events)}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥
            return self._parse_html_simple(html_content)
        
        return events
    
    def _parse_date_string(self, date_str: str) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤–∏–¥–∞ '6 –¥–µ–∫–∞–±—Ä—è 2025 00:00'"""
        try:
            # –ü–∞—Ä—Å–∏–º —Ñ–æ—Ä–º–∞—Ç "6 –¥–µ–∫–∞–±—Ä—è 2025 00:00"
            months_ru = {
                '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
                '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
                '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12,
                '—è–Ω–≤–∞—Ä—å': 1, '—Ñ–µ–≤—Ä–∞–ª—å': 2, '–º–∞—Ä—Ç': 3, '–∞–ø—Ä–µ–ª—å': 4,
                '–º–∞–π': 5, '–∏—é–Ω—å': 6, '–∏—é–ª—å': 7, '–∞–≤–≥—É—Å—Ç': 8,
                '—Å–µ–Ω—Ç—è–±—Ä—å': 9, '–æ–∫—Ç—è–±—Ä—å': 10, '–Ω–æ—è–±—Ä—å': 11, '–¥–µ–∫–∞–±—Ä—å': 12
            }
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω: "6 –¥–µ–∫–∞–±—Ä—è 2025 00:00"
            match = re.search(r'(\d{1,2})\s+(\w+)\s+(\d{4})\s+(\d{2}):(\d{2})', date_str)
            if match:
                day, month_ru, year, hour, minute = match.groups()
                month = months_ru.get(month_ru.lower())
                if month:
                    return datetime(int(year), month, int(day), int(hour), int(minute))
            
            # –ü—Ä–æ–±—É–µ–º –±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏: "6 –¥–µ–∫–∞–±—Ä—è 2025"
            match = re.search(r'(\d{1,2})\s+(\w+)\s+(\d{4})', date_str)
            if match:
                day, month_ru, year = match.groups()
                month = months_ru.get(month_ru.lower())
                if month:
                    return datetime(int(year), month, int(day), 0, 0)
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{date_str}': {e}")
        
        return None
    
    def _parse_html_simple(self, html_content: str) -> List[Dict]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ HTML –±–µ–∑ BeautifulSoup (fallback)"""
        events = []
        
        # –ò—â–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É <h1>...</h1>
        h1_pattern = r'<h1>(.*?)</h1>'
        time_pattern = r'<span>(\d{1,2}\s+\w+\s+\d{4}\s+\d{2}:\d{2})</span>'
        link_pattern = r'href="([^"]+)"'
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–æ–±—ã—Ç–∏—è –ø–æ div.b-content-event
        event_blocks = re.split(r'<div class="b-content-event">', html_content)
        
        for block in event_blocks[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Å—Ç–æ–π –±–ª–æ–∫
            event = {
                'title': '',
                'start_date': None,
                'end_date': None,
                'description': '',
                'author_uuids': [],
                'tags': [],
                'links': []
            }
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            h1_match = re.search(h1_pattern, block)
            if h1_match:
                event['title'] = re.sub(r'<[^>]+>', '', h1_match.group(1)).strip()
            
            # –î–∞—Ç–∞
            time_match = re.search(time_pattern, block)
            if time_match:
                date_str = time_match.group(1)
                event['start_date'] = self._parse_date_string(date_str)
            
            # –°—Å—ã–ª–∫–∏
            links = re.findall(link_pattern, block)
            for url in links:
                if 'example.com' in url:
                    event['links'].append(url)
                    parsed_url = urlparse(url)
                    query_params = parse_qs(parsed_url.query)
                    if 'authors' in query_params:
                        event['author_uuids'].extend(query_params['authors'])
                    if 'tags' in query_params:
                        event['tags'].extend(query_params['tags'])
            
            if event['title']:
                events.append(event)
        
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π –ø—Ä–æ—Å—Ç—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º: {len(events)}")
        return events
    
    async def get_books_by_author(self, author_uuid: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–Ω–∏–≥–∏ –∞–≤—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ GraphQL API"""
        query = """
        query GetBooksByAuthor($authorUuid: String!) {
          books(body: {
            authors: [$authorUuid]
            isActive: true
            limit: 5
          }) {
            uuid
            name
            slug
            annotation
            image {
              url
            }
          }
        }
        """
        
        variables = {"authorUuid": author_uuid}
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.graphql_endpoint,
                    json={"query": query, "variables": variables},
                    headers={"Content-Type": "application/json"},
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    if 'data' in data and 'books' in data['data']:
                        return data['data']['books']
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {e}")
        
        return []
    
    async def get_books_by_tag(self, tag: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–Ω–∏–≥–∏ –ø–æ —Ç–µ–≥—É —á–µ—Ä–µ–∑ GraphQL API"""
        query = """
        query GetBooksByTag($tagSlug: String!) {
          books(body: {
            isActive: true
            limit: 5
          }) {
            uuid
            name
            slug
          }
          tags(body: {
            slugs: [$tagSlug]
          }) {
            uuid
            name
            books(limit: 5) {
              uuid
              name
              slug
            }
          }
        }
        """
        
        variables = {"tagSlug": tag}
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.graphql_endpoint,
                    json={"query": query, "variables": variables},
                    headers={"Content-Type": "application/json"},
                    timeout=30.0
                )
                if response.status_code == 200:
                    data = response.json()
                    if 'data' in data:
                        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ tags
                        if 'tags' in data['data'] and data['data']['tags']:
                            tag_data = data['data']['tags'][0]
                            if 'books' in tag_data:
                                return tag_data['books']
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API –ø–æ —Ç–µ–≥—É: {e}")
        
        return []
    
    def format_event_message(self, event: Dict, books: List[Dict] = None) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å–æ–±—ã—Ç–∏–∏"""
        message_parts = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        message_parts.append(f"üìö <b>{event['title']}</b>\n")
        
        # –î–∞—Ç–∞
        if event['start_date']:
            date_str = event['start_date'].strftime("%d %B %Y")
            message_parts.append(f"üìÖ {date_str}\n")
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        if event['description']:
            desc = event['description'][:200]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            message_parts.append(f"{desc}\n")
        
        # –ö–Ω–∏–≥–∏
        if books:
            message_parts.append("\nüìñ <b>–ö–Ω–∏–≥–∏ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ ¬´–°–≤–µ—Ç¬ª:</b>")
            for book in books[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 –∫–Ω–∏–≥
                book_name = book.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                book_slug = book.get('slug', '')
                if book_slug:
                    book_url = f"https://example.com/catalog/{book_slug}"
                    message_parts.append(f"‚Ä¢ <a href='{book_url}'>{book_name}</a>")
                else:
                    message_parts.append(f"‚Ä¢ {book_name}")
        
        # –°—Å—ã–ª–∫–∏ –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
        if event['links']:
            message_parts.append("\nüîó <b>–°—Å—ã–ª–∫–∏:</b>")
            for link in event['links'][:3]:  # –ú–∞–∫—Å–∏–º—É–º 3 —Å—Å—ã–ª–∫–∏
                message_parts.append(f"<a href='{link}'>–û—Ç–∫—Ä—ã—Ç—å –≤ –∫–∞—Ç–∞–ª–æ–≥–µ</a>")
        
        return "\n".join(message_parts)
    
    async def get_today_events(self) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            from database import EventDatabase
            db = EventDatabase()
            
            today = datetime.now()
            db_events = db.get_events_by_date(today)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –±–æ—Ç–æ–º
            today_events = []
            for db_event in db_events:
                event = {
                    'title': db_event['title'],
                    'description': db_event['description'] or '',
                    'start_date': datetime.combine(db_event['event_date'], datetime.min.time()),
                    'author_uuids': [],
                    'tags': [],
                    'links': []
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∞–≤—Ç–æ—Ä–∞/—Ç–µ–≥/–∫–∞—Ç–µ–≥–æ—Ä–∏—é
                if db_event['reference_uuid']:
                    if db_event['event_type'] == 'author':
                        event['author_uuids'].append(db_event['reference_uuid'])
                        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫–Ω–∏–≥–∏ –∞–≤—Ç–æ—Ä–∞
                        event['links'].append(
                            f"https://example.com/catalog?authors={db_event['reference_uuid']}&page=1"
                        )
                    elif db_event['event_type'] == 'tag':
                        event['tags'].append(db_event['reference_uuid'])
                        event['links'].append(
                            f"https://example.com/catalog?tags={db_event['reference_uuid']}&page=1"
                        )
                    elif db_event['event_type'] == 'category':
                        event['links'].append(
                            f"https://example.com/catalog?categories={db_event['reference_uuid']}&page=1"
                        )
                
                today_events.append(event)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –∏–∑ –ë–î: {len(today_events)}")
            return today_events
            
        except ImportError:
            # Fallback –Ω–∞ –Ø–Ω–¥–µ–∫—Å –∫–∞–ª–µ–Ω–¥–∞—Ä—å, –µ—Å–ª–∏ –ë–î –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞
            logger.warning("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ø–Ω–¥–µ–∫—Å –∫–∞–ª–µ–Ω–¥–∞—Ä—å")
            xml_content = await self.fetch_calendar()
            all_events = self.parse_calendar(xml_content)
            
            today = datetime.now().date()
            today_events = []
            
            for event in all_events:
                if event['start_date']:
                    event_date = event['start_date'].date()
                    if event_date == today:
                        today_events.append(event)
            
            return today_events
    
    async def send_daily_digest(self):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Ä–∞—Å—Å—ã–ª–∫—É"""
        try:
            events = await self.get_today_events()
            
            if not events:
                logger.info("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –Ω–∞ —Å–µ–≥–æ–¥–Ω—è")
                return
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–±—ã—Ç–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
            for event in events:
                books = []
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–Ω–∏–≥–∏ –ø–æ –∞–≤—Ç–æ—Ä–∞–º
                for author_uuid in event['author_uuids']:
                    author_books = await self.get_books_by_author(author_uuid)
                    books.extend(author_books)
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–Ω–∏–≥–∏ –ø–æ —Ç–µ–≥–∞–º
                for tag in event['tags']:
                    tag_books = await self.get_books_by_tag(tag)
                    books.extend(tag_books)
                
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                seen_uuids = set()
                unique_books = []
                for book in books:
                    uuid = book.get('uuid')
                    if uuid and uuid not in seen_uuids:
                        seen_uuids.add(uuid)
                        unique_books.append(book)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                message = self.format_event_message(event, unique_books)
                
                try:
                    await self.bot.send_message(
                        chat_id=self.group_chat_id,
                        text=message,
                        parse_mode='HTML',
                        disable_web_page_preview=False
                    )
                    logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–±—ã—Ç–∏–µ: {event['title']}")
                    
                    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
                    await asyncio.sleep(1)
                    
                except TelegramError as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–∞—Å—Å—ã–ª–∫–∏: {e}")
    
    async def run_daily(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞—Å—Å—ã–ª–∫–∏"""
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ —Ä–µ–∂–∏–º–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞—Å—Å—ã–ª–∫–∏")
        
        while True:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ 9:00)
                now = datetime.now()
                if now.hour == 9 and now.minute == 0:
                    await self.send_daily_digest()
                    # –ñ–¥–µ–º —á–∞—Å, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
                    await asyncio.sleep(3600)
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                    await asyncio.sleep(60)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(60)


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    
    # ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
    # –ü–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ —É @BotFather –≤ Telegram
    BOT_TOKEN = "YOUR_BOT_TOKEN_HERE"
    
    # URL –∫–∞–ª–µ–Ω–¥–∞—Ä—è Yandex Calendar
    CALENDAR_URL = "https://calendar.yandex.ru/export/html.xml?private_token=<REDACTED>&tz_id=Europe/Moscow&limit=90"
    
    # URL GraphQL API (–Ω—É–∂–Ω–æ —É–∑–Ω–∞—Ç—å —É –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ API)
    GRAPHQL_ENDPOINT = "https://your-api-endpoint.com/graphql"
    
    # ID –≥—Ä—É–ø–ø—ã –≤ Telegram (–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å, –¥–æ–±–∞–≤–∏–≤ –±–æ—Ç–∞ @userinfobot –≤ –≥—Ä—É–ø–ø—É)
    GROUP_CHAT_ID = "YOUR_GROUP_CHAT_ID"
    # ======================
    
    bot = LiteraryCalendarBot(
        bot_token=BOT_TOKEN,
        calendar_url=CALENDAR_URL,
        graphql_endpoint=GRAPHQL_ENDPOINT,
        group_chat_id=GROUP_CHAT_ID
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Ä–∞—Å—Å—ã–ª–∫—É
    await bot.run_daily()


if __name__ == "__main__":
    asyncio.run(main())

